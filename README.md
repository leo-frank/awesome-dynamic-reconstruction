# Awesome Dynamic Reconstruction Resources 

A curated list of recent papers and open-source resources focused on non-rigid 3D general scene reconstruction from monocular images/videos, intended to keep pace with the anticipated surge of research in the coming months. 

If you have any additions or suggestions, feel free to contribute. Additional resources like blog posts, videos, etc. are also welcome.

## Table of contents
- [NeRF](#NeRF)
- [3DGS](#3DGS)
- [Overviews](#Overviews)
- [Seminar](#Seminar)


## NeRF
### 1. D-NeRF (CVPR 2021)
### 2. HyperNeRF: A Higher-Dimensional Representation for Topologically Varying Neural Radiance Fields.
### 3. Non-Rigid Neural Radiance Fields: Reconstruction and Novel View Synthesis of a Dynamic Scene From Monocular Video
### 4. Fast Dynamic Radiance Fields with Time-Aware Neural Voxels
### 5. Robust Dynamic Radiance Fields
### 6. Forward Flow for Novel View Synthesis of Dynamic Scenes
### 7. HexPlane: A Fast Representation for Dynamic Scenes (CVPR 2023)
### 8. K-Planes: Explicit Radiance Fields in Space, Time, and Appearance (CVPR 2023)
### 9. Neural 3D Video Synthesis from Multi-view Video (CVPR 2022 Oral)
### 10. Tensor4D: Efficient Neural 4D Decomposition for High-fidelity Dynamic Reconstruction and Rendering
### 11. Masked Space-Time Hash Encoding for Efficient Dynamic Scene Reconstruction
### 12. NSFF: Neural scene flow fields for space-time view synthesis of dynamic scenes (CVPR 2021)

### 13. DynIBaR: Neural Dynamic Image-Based Rendering (CVPR 2023 Best Paper Honorable Mention)
### 14. Space-time Neural Irradiance Fields for Free-Viewpoint Video (Jia-Bin Huang) (CVPR 2021)
### 15. Dynamic View Synthesis from Dynamic Monocular Video (ICCV 2021)
### 16. Neural Trajectory Fields for Dynamic Novel View Synthesis
### 17. Monocular Dynamic View Synthesis A Reality Check (Neurips 2022)
### 18. NeRFplayer
### 19. Semantic Attention Flow Fields for Monocular Dynamic Scene Decomposition (ICCV 2023)
### 20. Neuphysics: Editable neural geometry and physics from monocular videos (NeurIPS 2022)
### 21. Unbiased 4D: Monocular 4D Reconstruction with a Neural Deformation Model (CVPR Workshop 2023)
### 22. $D^2$NeRF$: Self-Supervised Decoupling of Dynamic and Static Objects from a Monocular Video
### 23. Improving the Convergence of Dynamic NeRFs via Optimal Transport (ICLR 2024)


## 3DGS
### 1. 4D Gaussian Splatting for Real-Time Dynamic Scene Rendering
### 2. CoGS : Controllable Gaussian Splatting
### 3. Dynamic 3D Gaussians: Tracking by Persistent Dynamic View Synthesis (3DV 2024)
### 4. Real-time Photorealistic Dynamic Scene Representation and Rendering with 4D Gaussian Splatting (ICLR 2024) 
### 5. ParticleNeRF: Particle Based Encoding for Online Neural Radiance Fields in Dynamic Scenes
### 6. Gaussian-Flow: 4D Reconstruction with Dynamic 3D Gaussian Particle
### 7. 4D Gaussian Splatting: Towards Efficient Novel View Synthesis for Dynamic Scenes (2024 0205) (åŒ—å¤§)
### 8.  GauFReðŸ§‡: Gaussian Deformation Fields for Real-time Dynamic Novel View Synthesis
### 9. DynMF: Neural Motion Factorization for Real-time Dynamic View Synthesis with 3D Gaussian Splatting
### 10. An Efficient 3D Gaussian Representation for Monocular/Multi-view Dynamic Scenes (January, 2023)
### 11. Deformable 3D Gaussians for High-Fidelity Monocular Dynamic Scene Reconstruction (2023 09)
### 12. Fast View Synthesis of Casual Videos
### 13. Spacetime Gaussian Feature Splatting for Real-Time Dynamic View Synthesis (2023 12)
### 14. SWAGS: Sampling Windows Adaptively for Dynamic 3D Gaussian Splatting


## Overviews:
### 1. State of the Art in Dense Monocular Non-Rigid 3D Reconstruction(EUROGRAPHICS State-of-the-Art Reports 2023)
### 2. Recent Trends in 3D Reconstruction of General Non-Rigid Scenes (EUROGRAPHICS State-of-the-Art Reports 2024)

## Seminar:

### 1. ðŸŽ¥ [Space-time Neural Irradiance Fields for Free-View Video](https://www.youtube.com/watch?v=kzmR3Njtwdg)
Presenter: Jia-Bin Huang, 01/20/2021
### 2. ðŸŽ¥ [Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic Scenes](https://www.youtube.com/watch?v=jYsVNtK4LNs&t=3319s)
Presenter: Zhengqi Li, 02/03/2021